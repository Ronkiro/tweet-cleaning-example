{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Need of processing the multilines in CSV manually:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "df = pd.read_csv('tweets.csv', sep=\";\", encoding=\"utf-16\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Letter Casing\r\n",
    "Converting all letters to either upper case or lower case."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "df['full_text'] = df['full_text'].apply(lambda s: s.lower())\r\n",
    "df['full_text'][0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'participei do @canalmynews, ontem. falei sobre o comportamento de bolsonaro na assembleia  geral da onu: passamos um vexame terrível!conversamos, também, sobre mais temas da política. vale muito a pena ver. segue o link: https://t.co/mme7idvnnc https://t.co/ihuuvlb1ej'"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizing \r\n",
    "Turning the tweets into tokens. Tokens are words separated by spaces in a text."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from nltk.tokenize import TweetTokenizer\r\n",
    "\r\n",
    "tknzr = TweetTokenizer()\r\n",
    "df['tk_text'] = df['full_text'].apply(lambda s: tknzr.tokenize(s))\r\n",
    "df[\"tk_text\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       [participei, do, @canalmynews, ,, ontem, ., fa...\n",
       "1       [@dicabairro, complicado, né, ,, se, fosse, só...\n",
       "2       [o, bate, boca, ,, os, xingamentos, ,, as, acu...\n",
       "3       [@bozistas, @steveemagal, @sabrinapinage, @elo...\n",
       "4       [as, coisas, no, seu, lugar, -, hhhuuummm, ......\n",
       "                              ...                        \n",
       "2863    [@flareis, @deltanmd, #acaboubolsonaro, #bolso...\n",
       "2864    [esse, cara, é, um, completo, babaca, ., sem, ...\n",
       "2865    [@castilho_ivete, o, bolsonaro, esta, perdido,...\n",
       "2866    [@johnnytb_, @paulo_souza35, @uol, bom, ,, se,...\n",
       "2867    [ipec, :, lula, aparece, na, liderança, nos, d...\n",
       "Name: tk_text, Length: 2868, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Noise removal\r\n",
    "Eliminating unwanted characters, such as HTML tags, punctuation marks, special characters, white spaces etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import string\r\n",
    "\r\n",
    "# remove punctuations\r\n",
    "df[\"tk_text\"] = df[\"tk_text\"].apply(lambda l: [s.translate(str.maketrans('','',string.punctuation)) for s in l])\r\n",
    "\r\n",
    "# remove noise\r\n",
    "df[\"tk_text\"] = df[\"tk_text\"].apply(lambda l: [s for s in l if s.isalpha()])\r\n",
    "df[\"tk_text\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       [participei, do, canalmynews, ontem, falei, so...\n",
       "1       [dicabairro, complicado, né, se, fosse, só, o,...\n",
       "2       [o, bate, boca, os, xingamentos, as, acusações...\n",
       "3       [bozistas, steveemagal, sabrinapinage, lauroja...\n",
       "4       [as, coisas, no, seu, lugar, hhhuuummm, empres...\n",
       "                              ...                        \n",
       "2863    [flareis, deltanmd, acaboubolsonaro, bolsonaro...\n",
       "2864    [esse, cara, é, um, completo, babaca, sem, ide...\n",
       "2865    [castilhoivete, o, bolsonaro, esta, perdido, e...\n",
       "2866    [johnnytb, uol, bom, se, vê, que, morreu, mais...\n",
       "2867    [ipec, lula, aparece, na, liderança, nos, dois...\n",
       "Name: tk_text, Length: 2868, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stopword removal\r\n",
    "Some words do not contribute much to the machine learning model, so it's good to remove them. A list of stopwords can be defined by the nltk library, or it can be business-specific."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import nltk\r\n",
    "nltk.download('stopwords')\r\n",
    "from nltk.corpus import stopwords\r\n",
    "swords = set(stopwords.words('portuguese') + [\"q\", \"né\", \"vc\", \"c\", \"n\", \"vcs\", \"eh\", \"pra\"])\r\n",
    "df[\"tk_text\"] = df[\"tk_text\"].apply(lambda l: [s for s in l if s not in swords])\r\n",
    "df[\"tk_text\"]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alexande\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       [participei, canalmynews, ontem, falei, sobre,...\n",
       "1       [dicabairro, complicado, supremo, votamos, bol...\n",
       "2       [bate, boca, xingamentos, acusações, revelaçõe...\n",
       "3       [bozistas, steveemagal, sabrinapinage, lauroja...\n",
       "4       [coisas, lugar, hhhuuummm, empresa, exesposa, ...\n",
       "                              ...                        \n",
       "2863    [flareis, deltanmd, acaboubolsonaro, bolsonaro...\n",
       "2864    [cara, completo, babaca, ideias, nenhuma, melh...\n",
       "2865    [castilhoivete, bolsonaro, perdido, sabe, lula...\n",
       "2866    [johnnytb, uol, bom, vê, morreu, bolsonaristas...\n",
       "2867    [ipec, lula, aparece, liderança, dois, cenário...\n",
       "Name: tk_text, Length: 2868, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stemming\r\n",
    "Stemming is the process of reducing the word to its root word. For example, the word \"running\" is reduced to \"run\"."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from nltk.stem import RSLPStemmer\r\n",
    "nltk.download('rslp')\r\n",
    "stemmer = RSLPStemmer()\r\n",
    "df[\"stemmed_text\"] = df[\"tk_text\"].apply(lambda l: [stemmer.stem(s) for s in l])\r\n",
    "df[\"stemmed_text\"] "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\alexande\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       [particip, canalmynew, ont, fal, sobr, comport...\n",
       "1       [dicabairr, complic, supr, vot, bolsonar, mud,...\n",
       "2       [bat, boc, xing, acus, revel, crim, entr, sen,...\n",
       "3       [bozist, steveemag, sabrinapinag, laurojardim,...\n",
       "4       [cois, lug, hhhuuummm, empr, exesp, capitã, bo...\n",
       "                              ...                        \n",
       "2863    [flarel, deltanmd, acaboubolsonar, bolsonarove...\n",
       "2864    [car, complet, babac, ide, nenhum, melhor, paí...\n",
       "2865    [castilhoivet, bolsonar, perd, sab, lul, lid, ...\n",
       "2866    [johnnytb, uol, bom, vê, morr, bolsonar, bolso...\n",
       "2867    [ipec, lul, aparec, lideranç, doi, cen, corr, ...\n",
       "Name: stemmed_text, Length: 2868, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "df.to_csv(\"clean_tweets.csv\", sep=\";\", encoding=\"utf-16\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('3.7.9': pyenv)"
  },
  "interpreter": {
   "hash": "ee40b1ce2efd0a8c0089220d7d2035392f8ece84f5a2eb7657f87280315cfc8f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}